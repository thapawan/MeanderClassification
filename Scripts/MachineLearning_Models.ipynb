#Load the CSV file:
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.svm import SVC
import seaborn as sns
import matplotlib.pyplot as plt

file_path = '/content/Inflection_Points_Meander_Classifications.csv'
data = pd.read_csv(file_path, low_memory=False, encoding='latin1')

#Preprocess the data
data['NMCI'] = data['NMCI'].replace(-9999, 0)
for column in ['Sinuosity', 'Amplitude (m)', 'Wavelength (m)', 'Water-surface width (m)', 'Meander length (m)', 'NMCI']:
    data[column] = pd.to_numeric(data[column], errors='coerce')

selected_provinces = ['COASTAL PLAIN', 'PIEDMONT', 'APPALACHIAN PLATEAUS']
data = data[data['Province'].isin(selected_provinces)]
data = data.dropna(subset=['Sinuosity', 'Amplitude (m)', 'Wavelength (m)', 'Water-surface width (m)', 'Meander length (m)', 'NMCI', 'Province'])

#Define meander classes and apply classification:
def classify_meander(row):
    if row['Water-surface width (m)'] < 50 and row['Sinuosity'] < 1.2 and row['Wavelength (m)'] < 5 * row['Water-surface width (m)'] and row['Amplitude (m)'] < 0.2 * row['Water-surface width (m)'] and row['Meander length (m)'] < 10 * row['Water-surface width (m)'] and row['QWBM (m³/s)'] < 0.1:
        return 'Incipient', 1
    elif 50 <= row['Water-surface width (m)'] < 100 and 1.2 <= row['Sinuosity'] < 1.5 and 5 * row['Water-surface width (m)'] <= row['Wavelength (m)'] < 10 * row['Water-surface width (m)'] and 0.2 * row['Water-surface width (m)'] <= row['Amplitude (m)'] < 0.5 * row['Water-surface width (m)'] and 10 * row['Water-surface width (m)'] <= row['Meander length (m)'] < 20 * row['Water-surface width (m)'] and 0.1 <= row['QWBM (m³/s)'] < 0.5:
        return 'Developing', 2
    elif 100 <= row['Water-surface width (m)'] < 250 and 1.5 <= row['Sinuosity'] < 2.0 and 10 * row['Water-surface width (m)'] <= row['Wavelength (m)'] < 20 * row['Water-surface width (m)'] and 0.5 * row['Water-surface width (m)'] <= row['Amplitude (m)'] < 1.0 * row['Water-surface width (m)'] and 20 * row['Water-surface width (m)'] <= row['Meander length (m)'] < 40 * row['Water-surface width (m)'] and 0.5 <= row['QWBM (m³/s)'] < 1.0:
        return 'Mature', 3
    elif 250 <= row['Water-surface width (m)'] < 500 and 2.0 <= row['Sinuosity'] < 3.0 and 20 * row['Water-surface width (m)'] <= row['Wavelength (m)'] < 40 * row['Water-surface width (m)'] and 1.0 * row['Water-surface width (m)'] <= row['Amplitude (m)'] < 1.5 * row['Water-surface width (m)'] and 40 * row['Water-surface width (m)'] <= row['Meander length (m)'] < 80 * row['Water-surface width (m)'] and 1.0 <= row['QWBM (m³/s)'] < 2.0:
        return 'Dynamic', 4
    elif row['Water-surface width (m)'] >= 500 and row['Sinuosity'] >= 3.0 and row['Wavelength (m)'] >= 40 * row['Water-surface width (m)'] and row['Amplitude (m)'] >= 1.5 * row['Water-surface width (m)'] and row['Meander length (m)'] >= 80 * row['Water-surface width (m)'] and row['QWBM (m³/s)'] >= 2.0:
        return 'Complex', 5
    else:
        if row['Water-surface width (m)'] < 100:
            return 'Incipient', 2
        elif row['Water-surface width (m)'] < 250:
            return 'Mature', 3
        elif row['Water-surface width (m)'] < 500:
            return 'Dynamic', 4
        else:
            return 'Complex', 5

data[['meander_class', 'meander_value']] = data.apply(classify_meander, axis=1, result_type='expand')

#Prepare data for meander classification
variables = ['Sinuosity', 'Amplitude (m)', 'Wavelength (m)', 'Water-surface width (m)', 'Meander length (m)', 'NMCI']
X = data[variables].fillna(0)
y = data['meander_value']

noise_factor = 0.4
X = X + noise_factor * np.random.normal(size=X.shape)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

#Initialize classifiers:
svm_clf = SVC()
gbm_clf = GradientBoostingClassifier(n_estimators=10, learning_rate=0.02, max_depth=1, min_samples_split=200, min_samples_leaf=150, random_state=42)
nn_clf = MLPClassifier(max_iter=1000)
dt_clf = DecisionTreeClassifier(max_depth=2, min_samples_split=300, min_samples_leaf=150, random_state=42)
rf_clf = RandomForestClassifier(n_estimators=50, max_depth=3, min_samples_split=30, min_samples_leaf=15, random_state=42)

#Train and evaluate classifiers
# Gradient Boosting Machine
gbm_clf.fit(X_train, y_train)
y_pred_gbm = gbm_clf.predict(X_test)
print("Gradient Boosting Machine Classification Report:")
print(classification_report(y_test, y_pred_gbm, zero_division=0))
print("Gradient Boosting Machine Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_gbm))

# Neural Network
nn_clf.fit(X_train, y_train)
y_pred_nn = nn_clf.predict(X_test)
print("Neural Network Classification Report:")
print(classification_report(y_test, y_pred_nn, zero_division=0))
print("Neural Network Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_nn))

# Decision Tree
dt_clf.fit(X_train, y_train)
y_pred_dt = dt_clf.predict(X_test)
print("Decision Tree Classification Report:")
print(classification_report(y_test, y_pred_dt, zero_division=0))
print("Decision Tree Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_dt))

# Random Forest
rf_clf.fit(X_train, y_train)
y_pred_rf = rf_clf.predict(X_test)
print("Random Forest Classification Report:")
print(classification_report(y_test, y_pred_rf, zero_division=0))
print("Random Forest Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_rf))
